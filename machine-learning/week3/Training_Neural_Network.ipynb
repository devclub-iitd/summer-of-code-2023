{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f0ed42",
   "metadata": {},
   "source": [
    "# Image Rotation Angle Prediction Model\n",
    "\n",
    "This notebook implements an image rotation angle prediction model using deep learning techniques. The model is trained on a dataset of images and their corresponding rotation angles.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "The following libraries are required to run the code successfully:\n",
    "\n",
    "- pandas: Used for data manipulation and analysis.\n",
    "- numpy: Used for mathematical operations on arrays.\n",
    "- tensorflow.keras.models.Sequential: The Keras Sequential model class for building the neural network model.\n",
    "- tensorflow.keras.layers: Contains various layers for constructing the neural network architecture.\n",
    "- tensorflow.keras.preprocessing.image.ImageDataGenerator: Used for real-time data augmentation and preprocessing of images.\n",
    "- sklearn.model_selection.train_test_split: Used for splitting the dataset into training and validation sets.\n",
    "\n",
    "Make sure these libraries are installed before running the code.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset used for training and validation is stored in a CSV file named 'augmented_data.csv'. The CSV file should contain two columns:\n",
    "\n",
    "- 'Image Address': Contains the file paths or URLs of the images.\n",
    "- 'Rotation Angle': Contains the rotation angles in degrees for each image.\n",
    "\n",
    "## Loading and Preprocessing the Dataset\n",
    "\n",
    "The code begins by importing the necessary libraries and loading the dataset using pandas. It then performs some preprocessing steps on the dataset:\n",
    "\n",
    "- Scaling the rotation angles: The rotation angles are scaled by adding 90 degrees and dividing by 5. This step ensures that the angles are within a suitable range for training the model.\n",
    "- Modifying image paths: The image paths are modified to replace backslashes with forward slashes to ensure compatibility with different operating systems.\n",
    "\n",
    "## ImageDataGenerator\n",
    "\n",
    "An ImageDataGenerator is created to perform real-time data augmentation and preprocessing. The generator is configured with the following parameters:\n",
    "\n",
    "- rescale: Normalizes the pixel values of the images between 0 and 1.\n",
    "- validation_split: Splits the data into training and validation sets based on the specified percentage.\n",
    "\n",
    "## Data Generators\n",
    "\n",
    "Two data generators are created using the ImageDataGenerator:\n",
    "\n",
    "- train_generator: Generates training data by flowing from the dataframe. It uses the training subset of the data.\n",
    "- validation_generator: Generates validation data by flowing from the dataframe. It uses the validation subset of the data.\n",
    "\n",
    "These generators automatically load images, preprocess them, and generate batches of images and their corresponding rotation angles for training and validation.\n",
    "\n",
    "## Neural Network Model\n",
    "\n",
    "The code defines a sequential neural network model using the Keras Sequential class. The model architecture consists of the following layers:\n",
    "\n",
    "- Conv2D: Applies convolutional filters to extract features from input images.\n",
    "- MaxPooling2D: Performs max pooling to downsample the feature maps.\n",
    "- Flatten: Flattens the feature maps into a 1D vector.\n",
    "- Dense: Fully connected layers for classification.\n",
    "- Activation: Activation functions applied to the outputs of the previous layers.\n",
    "\n",
    "The final layer uses a softmax activation function to predict the rotation angle from the available classes.\n",
    "\n",
    "## Training the Model\n",
    "\n",
    "The model is compiled with the Adam optimizer and the sparse categorical cross-entropy loss function. It is then trained using the `fit` function with the training generator. The number of epochs can be modified as needed.\n",
    "\n",
    "## Evaluating the Model\n",
    "\n",
    "The trained model is evaluated using the validation generator. The `evaluate` function returns the loss and accuracy metrics. These metrics indicate the performance of the model on the validation set.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to build and train a deep learning model for predicting rotation angles of images. By leveraging the power of convolutional neural networks and data augmentation, accurate predictions can be made for various rotation angles. The trained model can be further optimized or fine-tuned to improve performance on specific tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1f762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1581ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('./augmented_data.csv')\n",
    "data['Rotation Angle'] = (data['Rotation Angle'] + 90)/5\n",
    "data['Image Address'] = data['Image Address'].str.replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4738bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the image paths and rotation angles\n",
    "image_paths = data['Image Address'].tolist()\n",
    "rotation_angles = data['Rotation Angle'].tolist()\n",
    "\n",
    "# Define the desired image size\n",
    "image_width, image_height = 180, 240\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3d7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rotation angles to integer values\n",
    "rotation_angles = [int(angle) for angle in rotation_angles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c347d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Normalize pixel values between 0 and 1\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39250 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Create the data generator for training set\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=data,\n",
    "    x_col='Image Address',\n",
    "    y_col='Rotation Angle',\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=32,\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    class_mode='raw'  # Use 'raw' for integer labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50ebee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9812 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Create the data generator for validation set\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=data,\n",
    "    x_col='Image Address',\n",
    "    y_col='Rotation Angle',\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=32,\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    class_mode='raw'  # Use 'raw' for integer labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a4d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(37, activation='softmax'))  # Output layer with 37 classes for 37 possible angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3713ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da12b49d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1227/1227 [==============================] - 1762s 1s/step - loss: 0.0801 - accuracy: 0.9779 - val_loss: 0.0568 - val_accuracy: 0.9842\n",
      "Epoch 2/5\n",
      "1227/1227 [==============================] - 1719s 1s/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.1047 - val_accuracy: 0.9801\n",
      "Epoch 3/5\n",
      "1227/1227 [==============================] - 1733s 1s/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.1738 - val_accuracy: 0.9732\n",
      "Epoch 4/5\n",
      "1227/1227 [==============================] - 1711s 1s/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1119 - val_accuracy: 0.9820\n",
      "Epoch 5/5\n",
      "1227/1227 [==============================] - 1724s 1s/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.1785 - val_accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x296e9381a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=5, validation_data=validation_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ecf411e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 98s 320ms/step - loss: 0.1785 - accuracy: 0.9746\n",
      "Validation Loss: 0.17854377627372742\n",
      "Validation Accuracy: 0.974622905254364\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2980915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62a312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
