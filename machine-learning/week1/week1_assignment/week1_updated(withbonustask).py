# -*- coding: utf-8 -*-
"""Week1_Updated(withBonusTask).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v_D9ZnRmVlMGQG9JglrEIY7tXxV5-KO1

# Mobile Phone Price Prediction

Algorithms to be used:-

1.   Multiple Linear Regression

3.   Support Vector Regression(SVR)

1.   Decision Tree Regression

1.   Random Forest Regression

1.   XG Boost

1.   CatBoost

### Importing the Libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import r2_score

"""### Importing the Dataset"""

dataset = pd.read_csv('Mobile phone price.csv')
X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values
y = y.reshape(len(y),1)

"""### Data Preprocessing

### Encoding the Independent Variable
"""

# Create a DataFrame
df = pd.DataFrame(X, columns=['Brand', 'Storage', 'RAM', 'Screen Size', 'BatteryCapacity'])

# Perform one-hot encoding on the 'Brand' column
one_hot_encoded = pd.get_dummies(df['Brand'])

# Concatenate the one-hot encoded columns with the original DataFrame
df_encoded = pd.concat([df.drop('Brand', axis=1), one_hot_encoded], axis=1)

# Print the encoded DataFrame
print(df_encoded)

"""### Splitting the dataset into the Training set and Test set"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df_encoded, y, test_size = 0.2, random_state = 0)

"""## Multiple Linear Regression

Training the Multiple Linear Regression model on the Training set
"""

from sklearn.linear_model import LinearRegression
regressor_lr = LinearRegression()
regressor_lr.fit(X_train,y_train)

"""Predicting the Test Set Results"""

y_pred_lr = regressor_lr.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((y_pred_lr.reshape(len(y_pred_lr),1), y_test.reshape(len(y_test),1)),1))

"""Evaluating the Model Performance"""

r2_score(y_test, y_pred_lr)

"""## Support Vector Regression(SVR)

Training the Support Vector Regression model on the Training set
"""

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
sc_y = StandardScaler()
X_train_sc = sc_X.fit_transform(X_train)
y_train_sc = sc_y.fit_transform(y_train)
from sklearn.svm import SVR
regressor_svr = SVR(kernel = 'rbf')
regressor_svr.fit(X_train_sc, y_train_sc)

"""Predicting the Test Set Results"""

y_pred_svr = sc_y.inverse_transform(regressor_svr.predict(sc_X.transform(X_test)).reshape(-1,1))
np.set_printoptions(precision=2)
print(np.concatenate((y_pred_svr.reshape(len(y_pred_svr),1), y_test.reshape(len(y_test),1)),1))

"""Evaluating the Model Performance"""

r2_score(y_test, y_pred_svr)

"""## Decision Tree Regression

Training the Decision Tree Regression model on the Training set
"""

from sklearn.tree import DecisionTreeRegressor
regressor_dtr = DecisionTreeRegressor(random_state = 0)
regressor_dtr.fit(X_train, y_train)

"""Predicting the Test Set Results"""

y_pred_dtr = regressor_dtr.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((y_pred_dtr.reshape(len(y_pred_dtr),1), y_test.reshape(len(y_test),1)),1))

"""Evaluating the Model Performance"""

r2_score(y_test, y_pred_dtr)

"""##Random Forest Regression

Training the Random Forest Regression model on the Training set
"""

from sklearn.ensemble import RandomForestRegressor
regressor_rfr = RandomForestRegressor(n_estimators=10,random_state=0)
regressor_rfr.fit(X_train,y_train)

"""Predicting the Test Set Results"""

y_pred_rfr = regressor_rfr.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((y_pred_rfr.reshape(len(y_pred_rfr),1), y_test.reshape(len(y_test),1)),1))

"""Evaluating the Model Performance"""

r2_score(y_test, y_pred_rfr)

"""##XGBoost

Training the XGBoost Regression model on the Training set
"""

from xgboost import XGBRegressor
regressor_xb = XGBRegressor()
regressor_xb.fit(X_train_sc, y_train_sc)

"""Predicting the Test Set Results"""

y_pred_xb = sc_y.inverse_transform(regressor_xb.predict(sc_X.transform(X_test)).reshape(-1,1))
np.set_printoptions(precision=2)
print(np.concatenate((y_pred_xb.reshape(len(y_pred_xb),1), y_test.reshape(len(y_test),1)),1))

"""Evaluating the Model Performance"""

r2_score(y_test, y_pred_xb)

"""## CatBoost"""

!pip install catboost

"""Training the CatBoost Regression model on the Training set"""

from catboost import CatBoostRegressor
regressor_cb = CatBoostRegressor()
regressor_cb.fit(X_train, y_train)

"""Predicting the Test Set Results"""

y_pred_cb = regressor_cb.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((y_pred_cb.reshape(len(y_pred_cb),1), y_test.reshape(len(y_test),1)),1))

"""Evaluating the Model Performance"""

r2_score(y_test, y_pred_cb)

"""# Selection of the best Model

For comparison of our different models, we will use r2 Score
as our parameter:-


1.   Multiple Linear Regression - 0.824
1.   Support Vector Regression - 0.872
1.   Decision Tree Regression - 0.765
2.   Random Forest Regression - 0.830
5.   XGBoost - 0.865
5.   CatBoost - 0.887

So, clearly **CatBoost** is our best model with an amazing r2 score of 0.887.

## BONUS TASK - Exploratory Data Analysis(EDA)
"""

display(dataset)

"""###Plotting Bar Graph between Price and Brand"""

price = dataset['Price (in dollars)']
brand = dataset['Brand']
plt.figure(figsize=(12, 6))
plt.bar(brand,price)
plt.xlabel('Brand')
plt.ylabel('Price')
plt.title('Price vs Brand')
plt.show()

"""###Plotting Bar Graph between Price and Storage"""

price = dataset['Price (in dollars)']
storage = dataset['Storage(GB)']
plt.figure(figsize=(12, 4))
plt.bar(storage,price)
plt.xlabel('Storage(GB)')
plt.ylabel('Price')
plt.title('Price vs Storage')
plt.show()

"""###Plotting Bar Graph between Price and RAM"""

price = dataset['Price (in dollars)']
ram = dataset['RAM(GB)']
plt.figure(figsize=(12, 4))
plt.bar(ram,price)
plt.xlabel('RAM(GB)')
plt.ylabel('Price')
plt.title('Price vs RAM')
plt.show()

"""###Plotting Bar Graph between Price and Screen Size"""

price = dataset['Price (in dollars)']
screen_size = dataset['Screen Size (inches)']
plt.figure(figsize=(12, 4))
plt.bar(screen_size,price)
plt.xlabel('Screen Size (inches)')
plt.ylabel('Price')
plt.title('Price vs Screen Size')
plt.show()

"""###Plotting Bar Graph between Price and Battery Capacity"""

price = dataset['Price (in dollars)']
battery = dataset['Battery Capacity (mAh)']
plt.figure(figsize=(12, 4))
plt.bar(battery,price)
plt.xlabel('Battery Capacity (mAh)')
plt.ylabel('Price')
plt.title('Price vs Battery Capacity')
plt.show()

"""###Plotting Histogram between No. of Mobiles and Price


"""

import seaborn
seaborn.displot(dataset['Price (in dollars)'])

"""## Conclusions :-

* The price of mobile phones depends very much on their
  brand,we can observe that mobiles of Huawei, Apple and Samsung are much costlier than Realme,Motorola.

* More the Storage, more costlier the mobile phone is.

* More the RAM, more costlier the mobile phone is but 8GB
  RAM mobiles are costlier than 12GB RAM, may be due to the reason that 12GB RAM is not commonly offered by the premium brands.

* Nothing clear conclusion can be made w.r.t Battery
  Capacity.

* Cheaper mobile phones are clearly in more in number as
  most people want a affordable mobile phone for the day-to-day use.
"""